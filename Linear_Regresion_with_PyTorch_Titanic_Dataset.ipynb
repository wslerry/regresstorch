{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regresion with PyTorch - Titanic Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xGzlloM8dFx",
        "colab_type": "text"
      },
      "source": [
        "# **Linear Regresion with PyTorch**\n",
        "\n",
        "\n",
        "The dataset selected for this notebook is the Titanic dataset. \n",
        "\n",
        "This dataset has several information where each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex, and the fare they paid. Finally the dataset is devided in training and evaluation data.\n",
        "\n",
        "The training and evaluation data can be found in the following links:\n",
        "\n",
        "*   Training data: https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
        "*   Evaluation data: https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
        "\n",
        "This notebook is focused in the prediction of wheather a passenger survived or not, and it is build based on the following steps:\n",
        "\n",
        "1.   Install depencies\n",
        "2.   Import modules\n",
        "3. Download and dataset analysis\n",
        "4. Preparing the dataset for training\n",
        "5. Creating a Linear Regression model\n",
        "6. Training the model and fitting the data\n",
        "7. Making predictions using the trained model\n",
        "8. Saving the model\n",
        "9. Commiting and uploading the notebook\n",
        "\n",
        "This notebook is based on the concepts from the first two lectures and as part of the Assignment 2 of the course Deep Learning with PyTorch, which you can find in the following links:\n",
        "\n",
        "* Assignment 2 - Linear Regression: [click here](https://jovian.ml/fabianac07/assingment-02-linear-regression)  \n",
        "* Lecture 1: [click here](https://www.youtube.com/watch?v=vo_fUOk-IKk&list=LLaHOyHOvwkyZZw6dTitN1Vw&index=2&t=443s)\n",
        "* Lecture 2: [click here](https://www.youtube.com/watch?v=4ZZrP68yXCI)\n",
        "* PyTorch basics: https://jovian.ml/aakashns/01-pytorch-basics\n",
        "* Linear Regression: https://jovian.ml/aakashns/02-linear-regression\n",
        "* Logistic Regression: https://jovian.ml/aakashns/03-logistic-regression\n",
        "* Linear regression (minimal): https://jovian.ml/aakashns/housing-linear-minimal\n",
        "* Logistic regression (minimal): https://jovian.ml/aakashns/mnist-logistic-minimal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwrkSEzk8z2B",
        "colab_type": "text"
      },
      "source": [
        "#### Step 1: Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej8ERQzv8TUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c8d89e9-dbdc-4e1b-e218-e6690b01f62b"
      },
      "source": [
        "# Uncomment and run the commands below if imports fail\n",
        "# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
        "# !pip install matplotlib --upgrade --quiet\n",
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████                            | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.4MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS1d0O4G9CC7",
        "colab_type": "text"
      },
      "source": [
        "#### Step 2: Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_MNkJHq8dnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "12b54c55-2e4a-4d17-bf8b-6748d5768575"
      },
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eGH-4P89IoP",
        "colab_type": "text"
      },
      "source": [
        "#### Step 3: Download and Dataset Analysis \n",
        "\n",
        "To download the dataset the pandas `read_csv()` method is used. This method will download the dataset and turn it into a table. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdRx8TzxnjXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Load dataset '''\n",
        "dataset_training = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dataset_testing = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91DWz4giqe1Q",
        "colab_type": "text"
      },
      "source": [
        "It is possible to observe the data using pandas methods. \n",
        "The `.head()` method shows the first 5 items in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uSAEwWaqCT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9e13d63c-ce0f-4f1d-bce8-75dae93a6317"
      },
      "source": [
        "dataset_training.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  22.0  ...  unknown  Southampton      n\n",
              "1         1  female  38.0  ...        C    Cherbourg      n\n",
              "2         1  female  26.0  ...  unknown  Southampton      y\n",
              "3         1  female  35.0  ...        C  Southampton      n\n",
              "4         0    male  28.0  ...  unknown   Queenstown      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4HJFn_WqO0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7dfa9483-1bbe-4713-ce24-81d7719596ac"
      },
      "source": [
        "dataset_testing.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>First</td>\n",
              "      <td>E</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>D</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  35.0  ...  unknown  Southampton      y\n",
              "1         0    male  54.0  ...        E  Southampton      y\n",
              "2         1  female  58.0  ...        C  Southampton      y\n",
              "3         1  female  55.0  ...  unknown  Southampton      y\n",
              "4         1    male  34.0  ...        D  Southampton      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr1ONqmErmFO",
        "colab_type": "text"
      },
      "source": [
        "The `.describe()` method shows an statistical analysis of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nI_jviZq1hR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9f5ed6bc-ac6e-4e8e-f4de-c96342636d3e"
      },
      "source": [
        "dataset_training.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.387560</td>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.487582</td>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         survived         age  n_siblings_spouses       parch        fare\n",
              "count  627.000000  627.000000          627.000000  627.000000  627.000000\n",
              "mean     0.387560   29.631308            0.545455    0.379585   34.385399\n",
              "std      0.487582   12.511818            1.151090    0.792999   54.597730\n",
              "min      0.000000    0.750000            0.000000    0.000000    0.000000\n",
              "25%      0.000000   23.000000            0.000000    0.000000    7.895800\n",
              "50%      0.000000   28.000000            0.000000    0.000000   15.045800\n",
              "75%      1.000000   35.000000            1.000000    0.000000   31.387500\n",
              "max      1.000000   80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJBiGj-UrvVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "402155ac-f00e-491f-930f-eefe42e8bd9c"
      },
      "source": [
        "dataset_testing.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>264.000000</td>\n",
              "      <td>264.000000</td>\n",
              "      <td>264.000000</td>\n",
              "      <td>264.000000</td>\n",
              "      <td>264.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.375000</td>\n",
              "      <td>28.720985</td>\n",
              "      <td>0.469697</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>27.023880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.485042</td>\n",
              "      <td>14.157538</td>\n",
              "      <td>0.978393</td>\n",
              "      <td>0.837775</td>\n",
              "      <td>34.973108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>35.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>263.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         survived         age  n_siblings_spouses       parch        fare\n",
              "count  264.000000  264.000000          264.000000  264.000000  264.000000\n",
              "mean     0.375000   28.720985            0.469697    0.386364   27.023880\n",
              "std      0.485042   14.157538            0.978393    0.837775   34.973108\n",
              "min      0.000000    0.420000            0.000000    0.000000    0.000000\n",
              "25%      0.000000   21.000000            0.000000    0.000000    7.925000\n",
              "50%      0.000000   28.000000            0.000000    0.000000   13.250000\n",
              "75%      1.000000   35.250000            1.000000    0.000000   27.900000\n",
              "max      1.000000   74.000000            8.000000    6.000000  263.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coqnHL_vsCS4",
        "colab_type": "text"
      },
      "source": [
        "Machine learning is all about data, for this reason is very important to know what kind and how many data is available. \n",
        "\n",
        "For this reason is important to answer the following questions:\n",
        "\n",
        "***Q: How many rows does the training dataset have?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6-f_NMguTtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c520e4f2-1920-4d19-c261-a00d56adc182"
      },
      "source": [
        "num_rows = len(dataset_training.index)\n",
        "print('The number of rows on the training dataset is: ', num_rows)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of rows on the training dataset is:  627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKqFTSGrlCQ",
        "colab_type": "text"
      },
      "source": [
        "***Q: How many columns does the training dataset have?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJnIygNpuUk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07c38335-8c1d-4925-b721-151fdb2d6493"
      },
      "source": [
        "num_cols = len(dataset_training.columns)\n",
        "print('The number of columns on the training dataset is: ', num_cols)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of columns on the training dataset is:  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Zyv8VltsnC",
        "colab_type": "text"
      },
      "source": [
        "***Q: What are the column titles of the input variables?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCQ6vC4IuVty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3cd74c1b-5ac5-4e32-bc49-c714d7bc04a1"
      },
      "source": [
        "input_cols = dataset_testing.columns.values[1:]\n",
        "print('The columns titles of the input variables on the testing dataset are: ')\n",
        "print(input_cols)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The columns titles of the input variables on the testing dataset are: \n",
            "['sex' 'age' 'n_siblings_spouses' 'parch' 'fare' 'class' 'deck'\n",
            " 'embark_town' 'alone']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JDq1Kstt4TU",
        "colab_type": "text"
      },
      "source": [
        "***Q: What is the column title of the output/target variable in the training dataset?***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv45V28yuWbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8349a7c6-cce0-4979-eb85-304eb71ded0f"
      },
      "source": [
        "output_cols = dataset_training.columns.values[:1]\n",
        "print('The target column title on the training dataset is: ', output_cols)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The target column title on the training dataset is:  ['survived']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4k6MIfCuASV",
        "colab_type": "text"
      },
      "source": [
        "***Q: Which of the input columns are categorical (on-numerical variables) in the training dataset?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhCYs1XpuXSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4df9d27-aba4-4cf7-9218-315ed25bcf01"
      },
      "source": [
        "categorical_cols = dataset_training.select_dtypes(include=object).columns.values\n",
        "print('The non-numerical columns in the training dataset are: ')\n",
        "print(categorical_cols)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The non-numerical columns in the training dataset are: \n",
            "['sex' 'class' 'deck' 'embark_town' 'alone']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx5VTweUxNJT",
        "colab_type": "text"
      },
      "source": [
        "***Q: How would you plot the distributions of survivors and age of the passengers?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpP6KWG3xH5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c9788a23-dbc9-4046-d229-4da2b5700d80"
      },
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt.title('Distribution of survivors among passenges in training dataset')\n",
        "sns.distplot(dataset_training.survived, bins=2, kde=False);"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulyz4s5sxrof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d377cbaa-9dd9-4591-ad47-988d3e25ca46"
      },
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt.title('Distribution of age among passenges in training dataset')\n",
        "sns.distplot(dataset_training.age, bins=20, kde=False);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Cq_xDp51k6",
        "colab_type": "text"
      },
      "source": [
        "#### Step 4: Preparing the Dataset for Training\n",
        "\n",
        "By this point it was observed that the data has been handle in Pandas form. To process the training data, it has to be converted into PyTorch tensors. \n",
        "\n",
        "To do so, it is necessary to convert it to numpy arrayas, and the following function will do that for us:\n",
        "\n",
        "*To understand how tha categorical data is converted into numbers refer to [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euAR5g545bpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVSC68947ijs",
        "colab_type": "text"
      },
      "source": [
        "Now it is just a matter to pass trough the `dataframe_to_arrays` function the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vl6ZZb07uaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce16a76a-bfbd-4482-896c-973dd9fda5b2"
      },
      "source": [
        "inputs_array_training, targets_array_training = dataframe_to_arrays(dataset_training)\n",
        "print(inputs_array_training)\n",
        "print(targets_array_training)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1. 22.  1. ...  7.  2.  0.]\n",
            " [ 0. 38.  1. ...  2.  0.  0.]\n",
            " [ 0. 26.  0. ...  7.  2.  1.]\n",
            " ...\n",
            " [ 0. 19.  0. ...  1.  2.  1.]\n",
            " [ 0. 28.  1. ...  7.  2.  0.]\n",
            " [ 1. 32.  0. ...  7.  1.  1.]]\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDSqLP1gBo7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3fce48e-ad9b-41da-86f6-31aeee24a4d3"
      },
      "source": [
        "inputs_array_testing, targets_array_testing = dataframe_to_arrays(dataset_testing)\n",
        "print(inputs_array_testing)\n",
        "print(targets_array_testing)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1. 35.  0. ...  6.  2.  1.]\n",
            " [ 1. 54.  0. ...  4.  2.  1.]\n",
            " [ 0. 58.  0. ...  2.  2.  1.]\n",
            " ...\n",
            " [ 0. 39.  0. ...  6.  1.  0.]\n",
            " [ 1. 27.  0. ...  6.  2.  1.]\n",
            " [ 1. 26.  0. ...  2.  0.  1.]]\n",
            "[[0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufH0BshX9AVV",
        "colab_type": "text"
      },
      "source": [
        "The next thing to do is to convert the numpy arrays into PyTorch tensors.\n",
        "\n",
        "*NOTE: The tensor data type must be `torch.float32`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ntyKtqt7wpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7fec157-6f9d-4683-909b-40c0801e56fd"
      },
      "source": [
        "# Import from numpy arrays to pytorch\n",
        "inputs_training = torch.from_numpy(inputs_array_training).type(torch.float32)\n",
        "targets_training = torch.from_numpy(targets_array_training).type(torch.float32)\n",
        "inputs_training.dtype, targets_training.dtype"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhBK7IO6Bz_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f86ea352-8499-45af-8d75-0f92884a34d8"
      },
      "source": [
        "inputs_testing = torch.from_numpy(inputs_array_testing).type(torch.float32)\n",
        "targets_testing = torch.from_numpy(targets_array_testing).type(torch.float32)\n",
        "inputs_testing.dtype, targets_testing.dtype"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlgFva0O-hlg",
        "colab_type": "text"
      },
      "source": [
        "Now, create PyTorch datasets for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpTU1SyQ9XUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(inputs_training, targets_training)\n",
        "val_dataset = TensorDataset(inputs_testing, targets_testing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjBs0tMmDGbO",
        "colab_type": "text"
      },
      "source": [
        "Finally, create dataloaders for training and validation.\n",
        "\n",
        "To do so, it is necessary to select a batch size for the data loader. This means that the loader will not feed the whole dataset to the model at once, but it will feed the model with small entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUFpL1LCD-va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch Size for data loader\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiUxwM8OCNi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size*2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZVcrp_9EboA",
        "colab_type": "text"
      },
      "source": [
        "It is possible to verify that the data loader worked well by running the following loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJylNafEowa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c23d6426-96be-44e4-c972-bae0cae47859"
      },
      "source": [
        "print('Data inside the training data loader: ')\n",
        "for x_i, y_i in train_loader:\n",
        "  print(\"inputs\", x_i)\n",
        "  print(\"targets\", y_i)\n",
        "  break"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data inside the training data loader: \n",
            "inputs tensor([[  0.0000,  30.0000,   0.0000,   0.0000,   8.6625,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  22.0000,   0.0000,   0.0000, 151.5500,   0.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.5000,   0.0000,   0.0000,   7.2292,   2.0000,   7.0000,\n",
            "           0.0000,   1.0000],\n",
            "        [  1.0000,  36.0000,   0.0000,   0.0000,  10.5000,   1.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  38.0000,   0.0000,   0.0000,  80.0000,   0.0000,   1.0000,\n",
            "           3.0000,   1.0000],\n",
            "        [  0.0000,  31.0000,   1.0000,   0.0000, 113.2750,   0.0000,   3.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   0.0000,   1.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  22.0000,   0.0000,   0.0000,   7.2500,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  22.0000,   0.0000,   2.0000,  49.5000,   0.0000,   1.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  29.0000,   0.0000,   0.0000,   9.4833,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,   3.0000,   1.0000,   2.0000,  41.5792,   1.0000,   7.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  0.0000,  28.0000,   1.0000,   0.0000,  15.5000,   2.0000,   7.0000,\n",
            "           1.0000,   0.0000],\n",
            "        [  1.0000,  42.0000,   1.0000,   0.0000,  27.0000,   1.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  23.0000,   0.0000,   0.0000,   7.8542,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  24.0000,   0.0000,   1.0000, 247.5208,   0.0000,   1.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  16.0000,   0.0000,   0.0000,   8.0500,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,  30.6958,   0.0000,   7.0000,\n",
            "           0.0000,   1.0000],\n",
            "        [  0.0000,  28.0000,   0.0000,   0.0000,   7.7500,   2.0000,   7.0000,\n",
            "           1.0000,   1.0000],\n",
            "        [  1.0000,  23.0000,   0.0000,   0.0000,  15.0458,   1.0000,   7.0000,\n",
            "           0.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   8.0500,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,  56.4958,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  28.0000,   1.0000,   0.0000,  16.1000,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  0.0000,  28.0000,   0.0000,   0.0000,   7.8792,   2.0000,   7.0000,\n",
            "           1.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   1.0000,   0.0000,  19.9667,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  28.0000,   1.0000,   2.0000,  23.4500,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,   3.0000,   1.0000,   1.0000,  26.0000,   1.0000,   5.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   7.7750,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  28.0000,   1.0000,   0.0000,  89.1042,   0.0000,   2.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  43.0000,   0.0000,   0.0000,   8.0500,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  30.0000,   3.0000,   0.0000,  21.0000,   1.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  20.0000,   0.0000,   0.0000,   9.2250,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  41.0000,   0.0000,   5.0000,  39.6875,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  0.0000,  24.0000,   0.0000,   3.0000,  19.2583,   2.0000,   7.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  32.0000,   0.0000,   0.0000,   7.7500,   2.0000,   7.0000,\n",
            "           1.0000,   1.0000],\n",
            "        [  0.0000,   5.0000,   0.0000,   0.0000,  12.4750,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  17.0000,   0.0000,   0.0000,   8.6625,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,  56.4958,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  21.0000,   0.0000,   0.0000,  77.9583,   0.0000,   3.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  50.0000,   0.0000,   0.0000,  10.5000,   1.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   1.0000,  33.0000,   1.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  34.0000,   0.0000,   0.0000,  13.0000,   1.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  71.0000,   0.0000,   0.0000,  49.5042,   0.0000,   7.0000,\n",
            "           0.0000,   1.0000],\n",
            "        [  1.0000,  30.0000,   1.0000,   0.0000,  24.0000,   1.0000,   7.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  34.5000,   0.0000,   0.0000,   6.4375,   2.0000,   7.0000,\n",
            "           0.0000,   1.0000],\n",
            "        [  1.0000,  35.0000,   0.0000,   0.0000,   8.0500,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,   7.0000,   4.0000,   1.0000,  29.1250,   2.0000,   7.0000,\n",
            "           1.0000,   0.0000],\n",
            "        [  1.0000,  20.0000,   0.0000,   0.0000,   9.8458,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   7.8958,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  54.0000,   1.0000,   0.0000,  59.4000,   0.0000,   7.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  23.0000,   0.0000,   0.0000,  13.0000,   1.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   8.0500,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  27.0000,   0.0000,   2.0000,  11.1333,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  40.5000,   0.0000,   2.0000,  14.5000,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  18.0000,   1.0000,   0.0000, 108.9000,   0.0000,   2.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   7.8958,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  0.0000,  17.0000,   4.0000,   2.0000,   7.9250,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  27.0000,   0.0000,   0.0000,   7.8958,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   1.0000,   0.0000,  15.8500,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   7.7500,   2.0000,   7.0000,\n",
            "           1.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   8.0000,   2.0000,  69.5500,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  34.0000,   1.0000,   1.0000,  14.4000,   2.0000,   7.0000,\n",
            "           2.0000,   0.0000],\n",
            "        [  1.0000,  18.0000,   0.0000,   0.0000,   8.3000,   2.0000,   7.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  35.0000,   0.0000,   0.0000,  26.2875,   0.0000,   4.0000,\n",
            "           2.0000,   1.0000],\n",
            "        [  1.0000,  28.0000,   0.0000,   0.0000,   8.4583,   2.0000,   7.0000,\n",
            "           1.0000,   1.0000]])\n",
            "targets tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJRy--0fFGYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5004b505-b55e-417c-f8c2-03c9433bc5be"
      },
      "source": [
        "print('Data inside the validation data loader: ')\n",
        "for x_o, y_o in val_loader:\n",
        "  print(\"inputs\", x_o)\n",
        "  print(\"targets\", y_o)\n",
        "  break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data inside the validation data loader: \n",
            "inputs tensor([[ 1., 35.,  0.,  ...,  6.,  2.,  1.],\n",
            "        [ 1., 54.,  0.,  ...,  4.,  2.,  1.],\n",
            "        [ 0., 58.,  0.,  ...,  2.,  2.,  1.],\n",
            "        ...,\n",
            "        [ 1., 28.,  0.,  ...,  6.,  2.,  1.],\n",
            "        [ 0., 50.,  0.,  ...,  6.,  2.,  1.],\n",
            "        [ 1., 28.,  0.,  ...,  6.,  1.,  1.]])\n",
            "targets tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR4Np2QmFU5U",
        "colab_type": "text"
      },
      "source": [
        "#### Step 5: Creating the Linear Regression Model\n",
        "\n",
        "This a fairly straightforward linear regression model. \n",
        "\n",
        "First, it is necessary to define how many columns are in the input and output variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSLiq2UvFwzh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2236a015-0e0d-4850-ef66-77f43db74039"
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)\n",
        "input_cols, output_cols"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class',\n",
              "        'deck', 'embark_town', 'alone'], dtype=object),\n",
              " array(['survived'], dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHZ6QK4dJzu5",
        "colab_type": "text"
      },
      "source": [
        "Second, it is necesary to define a class where the model will be build.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPQgfZyQFzJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TitanicModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size) \n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                          \n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        #loss = F.l1_loss(out, targets) \n",
        "        loss = F.mse_loss(out, targets)                          \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        #loss = F.l1_loss(out, targets)   \n",
        "        loss = F.mse_loss(out, targets)                           \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean() \n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1sg50jVNvQf",
        "colab_type": "text"
      },
      "source": [
        "Then, it is just a matter of build the model and check its initial weights and biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94XMPItQF8dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TitanicModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxJbCeLGBe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "61c3122b-a7a4-41f4-fb7d-ee6e90b3047b"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.1652,  0.0280,  0.2494, -0.2080,  0.2956,  0.1605, -0.0413,  0.3330,\n",
              "          -0.1175]], requires_grad=True), Parameter containing:\n",
              " tensor([0.1035], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE7TSQ-MGMX3",
        "colab_type": "text"
      },
      "source": [
        "#### Step 6: Training the Model and Fitting the Data\n",
        "\n",
        "To train the model, it is necesary to define the `evaluate` function, which will perform the validation of the model, and the `fit` function, which will perform the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAI8bkIfGewk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bl07TpnOnv_",
        "colab_type": "text"
      },
      "source": [
        "The `fit` function records the validation loss and metric from each epoch and returns a history of the training process. This is useful for debuggin & visualizing the training process. \n",
        "\n",
        "Configurations like batch size and learning rate need to be selected in advance while training machine learning models, and are called hyperparameters. \n",
        "\n",
        "Selecting the right hyperparameters is critical for training an accurate model within a reasonable amount of time, and is an active area of research and experimentation. Feel free to try different learning rates and see how it affects the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udmUAA9lGiy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e020a4f-7ce4-4214-878b-b02bd7b6af37"
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 185.7541961669922}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIZag6DTGpIP",
        "colab_type": "text"
      },
      "source": [
        "At this point the model is ready to be trained.It may be necessary to run the training loops many times, for different number of epochs and with different learning rates, to get a good result. \n",
        "\n",
        "*NOTE: If the loss becomes too large (or `nan`), it might be necessary to re-initialize the model by running the cell `model = InsuranceModel()`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAfEwiAmGjc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4c784f4c-35bc-4653-e65e-cd5f40242ea2"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-4\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 0.6428\n",
            "Epoch [40], val_loss: 0.5909\n",
            "Epoch [60], val_loss: 0.7017\n",
            "Epoch [80], val_loss: 0.5255\n",
            "Epoch [100], val_loss: 0.4987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34cG14QG0xT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f8b2ebe5-b55b-4c3f-8298-bd7833b52cc4"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-4\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 0.4799\n",
            "Epoch [40], val_loss: 0.4913\n",
            "Epoch [60], val_loss: 0.4446\n",
            "Epoch [80], val_loss: 0.4453\n",
            "Epoch [100], val_loss: 0.4254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNR8uzC_G0kF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a5cfc2a5-f3b3-495f-f650-0d8885b74237"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-5\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 0.4177\n",
            "Epoch [40], val_loss: 0.4157\n",
            "Epoch [60], val_loss: 0.4153\n",
            "Epoch [80], val_loss: 0.4134\n",
            "Epoch [100], val_loss: 0.4119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plxUXKIG0VT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e4b3f80e-ff73-482d-f4ec-13acab545e61"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-5\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 0.4108\n",
            "Epoch [40], val_loss: 0.4098\n",
            "Epoch [60], val_loss: 0.4089\n",
            "Epoch [80], val_loss: 0.4076\n",
            "Epoch [100], val_loss: 0.4072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6yPtCPNHRJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "75a1faac-38d2-4fb7-ad3e-8170da0a804f"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-6\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 0.4062\n",
            "Epoch [40], val_loss: 0.4060\n",
            "Epoch [60], val_loss: 0.4058\n",
            "Epoch [80], val_loss: 0.4057\n",
            "Epoch [100], val_loss: 0.4056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98dlYMJ1GojV",
        "colab_type": "text"
      },
      "source": [
        "Once the model is trained, it might be necesary to report the final validation loss of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBxNUHjfK0pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71e33aa1-188f-4df5-81c1-aaba8c8e3369"
      },
      "source": [
        "val_loss = history5[-1]\n",
        "print('The final validation loss is: ', val_loss)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The final validation loss is:  {'val_loss': 0.405606746673584}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhtML8cbLLTQ",
        "colab_type": "text"
      },
      "source": [
        "If it is necessary to plot the whole training history, it would be just a matter to run the following lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPbu-W0LLHHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "97e25425-0539-42b8-98cb-93fe7285ae36"
      },
      "source": [
        "whole_history = [result] + history1 + history2 + history3 + history4 + history5\n",
        "losses = [r['val_loss'] for r in whole_history]\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.grid('on')\n",
        "plt.title('Loss Value vs Training Epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('losses')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'losses')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGElLUkmLmJx",
        "colab_type": "text"
      },
      "source": [
        "#### Step 7: Making Predictions Using the Trained Model\n",
        "\n",
        "To make predictions using the trained model it would be necesary to define the `predict_single` function, which will take as input a row from the validation dataset and make the prediction of whether the passenger survived or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDGF_otqLlQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(input)                # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)\n",
        "    if prediction >= 0.5:\n",
        "      print('The passenger survived!')\n",
        "    else:\n",
        "      print('Tha passenger did not survived...')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp0xOsTuRYzX",
        "colab_type": "text"
      },
      "source": [
        "To see if the predictions are correct, it is possible to print the frist 5 rows of the testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69hMgP-WNw3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "731d1cc8-3789-4a78-83ed-c18ebaf4d4ea"
      },
      "source": [
        "dataset_testing.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>First</td>\n",
              "      <td>E</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>D</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  35.0  ...  unknown  Southampton      y\n",
              "1         0    male  54.0  ...        E  Southampton      y\n",
              "2         1  female  58.0  ...        C  Southampton      y\n",
              "3         1  female  55.0  ...  unknown  Southampton      y\n",
              "4         1    male  34.0  ...        D  Southampton      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_aAl8j1RmOV",
        "colab_type": "text"
      },
      "source": [
        "Now, it is just a matter of selecting which row of the validation dataset will pass throught the `predict_single` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAeaYROOLOv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "50ad89a8-984c-4a23-b311-5a044cb35839"
      },
      "source": [
        "input, target = val_dataset[0]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([ 1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000,  6.0000,  2.0000,\n",
            "         1.0000])\n",
            "Target: tensor([0.])\n",
            "Prediction: tensor(0.4714)\n",
            "Tha passenger did not survived...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYk_zWpKL5Ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "45e33004-d5d4-44a8-a10f-4f818cad5900"
      },
      "source": [
        "input, target = val_dataset[1]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([ 1.0000, 54.0000,  0.0000,  0.0000, 51.8625,  0.0000,  4.0000,  2.0000,\n",
            "         1.0000])\n",
            "Target: tensor([0.])\n",
            "Prediction: tensor(0.5506)\n",
            "The passenger survived!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_fbnE20L7FJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0f1e565f-c104-4557-dead-9c5cca13ae6f"
      },
      "source": [
        "input, target = val_dataset[2]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([ 0.0000, 58.0000,  0.0000,  0.0000, 26.5500,  0.0000,  2.0000,  2.0000,\n",
            "         1.0000])\n",
            "Target: tensor([1.])\n",
            "Prediction: tensor(0.5233)\n",
            "The passenger survived!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWfCCev0SI-e",
        "colab_type": "text"
      },
      "source": [
        "#### Step 8: Saving the Model\n",
        "\n",
        "To save the model, it is just a matter to run the following lines. This will save the model in the local folder and it is possible to load it in the future. \n",
        "\n",
        "This will save time and computational resourses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WArpajECQxkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'titanic_linear_regresion_model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89t4X8_OSqjC",
        "colab_type": "text"
      },
      "source": [
        "The `.state_dict` method returns an `OrderedDict` containing all the weights and bias matrices mapped to the right attributes of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UKZXZ6ITPWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d4a82d88-9919-4f02-a1e5-8e539739daef"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight',\n",
              "              tensor([[ 0.0916,  0.0020,  0.1306, -0.1942,  0.0030,  0.1127, -0.0668,  0.2376,\n",
              "                       -0.1172]])),\n",
              "             ('linear.bias', tensor([0.1039]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5s5EZ9ZSyiU",
        "colab_type": "text"
      },
      "source": [
        "To load the model weights, it is just a matter of creating a new object of the class `TitanicModel`, and use the `.load_state_dict` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdO_yZSkTFES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "586f8698-038f-4939-ac54-c537817be00d"
      },
      "source": [
        "model2 = TitanicModel()\n",
        "model2.load_state_dict(torch.load('titanic_linear_regresion_model.pth'))\n",
        "model2.state_dict()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight',\n",
              "              tensor([[ 0.0916,  0.0020,  0.1306, -0.1942,  0.0030,  0.1127, -0.0668,  0.2376,\n",
              "                       -0.1172]])),\n",
              "             ('linear.bias', tensor([0.1039]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7T42_ZsTTd9",
        "colab_type": "text"
      },
      "source": [
        "Finally, it is possible to verify that the model has the same loss than in the validation test above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzNZy3sxTFbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df349f3d-5dae-48c2-88f3-3e9b846f3b10"
      },
      "source": [
        "test_loader = DataLoader(val_dataset, batch_size=32)\n",
        "result = evaluate(model2, test_loader)\n",
        "result"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 0.33652156591415405}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3S4qGBpYZIR",
        "colab_type": "text"
      },
      "source": [
        "#### Step 9: Commit and Upload the Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t-p25y0Yjv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b78867b2-ee75-49bd-d70e-f80bd918d167"
      },
      "source": [
        "jovian.commit(project='titanic-linear-regression', environment=None, outputs=['titanic_linear_regresion_model.pth'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[jovian] Error: Failed to detect Jupyter notebook or Python script. Skipping..\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBrVv3MrVEFx",
        "colab_type": "text"
      },
      "source": [
        "## Summary and Further Reading\n",
        "\n",
        "In this notebook a simple linear regression model created in PyTorch is preseted. The list of the topics covered is the following:\n",
        "\n",
        "\n",
        "\n",
        "*   Download and access data using Pandas\n",
        "*   Creation of Linear Models with PyTorch\n",
        "*   How to fit and train the linear model\n",
        "*   How to test the trained model\n",
        "*   How to save the model for further usage\n",
        "\n",
        "There is a fairly amount of data and code to experiment in this notebook. It is open for the readers to modify it and play arround with the model.\n",
        "\n",
        "Finally, here are some references and links for further reading:\n",
        "\n",
        "\n",
        "\n",
        "1.   Free Course - [Deep Learning with PyTorch](https://www.youtube.com/playlist?list=LLaHOyHOvwkyZZw6dTitN1Vw) \n",
        "2.   Learn more about [Linear Regression](https://en.wikipedia.org/wiki/Linear_regression#:~:text=In%20statistics%2C%20linear%20regression%20is,is%20called%20simple%20linear%20regression.)\n",
        "3.   Course Notes - [CS109: Intro to Probability for Computer Scientists](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/)\n",
        "4.   [A Titanic Probability](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}